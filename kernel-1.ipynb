{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('../input/train-csv/legend.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "_uuid": "9c1288f883078dc82085f6662483988db73aed29",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_csv['emotion'] = train_csv['emotion'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "_uuid": "6f7a89d5822dc981b92d08f56d3083d032d7463f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user.id</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contempt</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happiness</th>\n",
       "      <td>5696</td>\n",
       "      <td>5696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>6868</td>\n",
       "      <td>6868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user.id  image\n",
       "emotion                  \n",
       "anger          252    252\n",
       "contempt         9      9\n",
       "disgust        208    208\n",
       "fear            21     21\n",
       "happiness     5696   5696\n",
       "neutral       6868   6868\n",
       "sadness        268    268\n",
       "surprise       368    368"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.groupby('emotion').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "_uuid": "ae405ec8cf82dd5a864f3aab22f3c4f554955e80",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_csv.replace(\"contempt\", \"anger\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "_uuid": "c3d14d4d03d23c0d40e19ddc5049e6cb725d237a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user.id</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happiness</th>\n",
       "      <td>5696</td>\n",
       "      <td>5696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>6868</td>\n",
       "      <td>6868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user.id  image\n",
       "emotion                  \n",
       "anger          261    261\n",
       "disgust        208    208\n",
       "fear            21     21\n",
       "happiness     5696   5696\n",
       "neutral       6868   6868\n",
       "sadness        268    268\n",
       "surprise       368    368"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.groupby('emotion').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "_uuid": "6e36c1b89f68b736aa4c5179de97537898447493",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping_emotion = {'anger': 0, 'disgust': 1, 'fear': 2, 'happiness': 3, 'neutral': 6, 'sadness': 4, 'surprise': 5}\n",
    "train_csv['label'] = train_csv['emotion'].map(mapping_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "_uuid": "4866e533f18821fc45380fcd3aff47afd93c2661"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user.id</th>\n",
       "      <th>image</th>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628</td>\n",
       "      <td>facial-expressions_2868588k.jpg</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628</td>\n",
       "      <td>facial-expressions_2868585k.jpg</td>\n",
       "      <td>surprise</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>628</td>\n",
       "      <td>facial-expressions_2868584k.jpg</td>\n",
       "      <td>disgust</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>628</td>\n",
       "      <td>facial-expressions_2868582k.jpg</td>\n",
       "      <td>fear</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dwdii</td>\n",
       "      <td>Aaron_Eckhart_0001.jpg</td>\n",
       "      <td>neutral</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user.id                            image   emotion  label\n",
       "0     628  facial-expressions_2868588k.jpg     anger      0\n",
       "1     628  facial-expressions_2868585k.jpg  surprise      5\n",
       "2     628  facial-expressions_2868584k.jpg   disgust      1\n",
       "3     628  facial-expressions_2868582k.jpg      fear      2\n",
       "4   dwdii           Aaron_Eckhart_0001.jpg   neutral      6"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "_uuid": "de4e9948ceb85a1bb5de3176fd066103ddcb1cdf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2 as cv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "_uuid": "f02394cc36b771108af2ae8d8a12639cab99ff89",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained = '../input/trainedimages'\n",
    "#os.mkdir(trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "_uuid": "73ab220270f57bb9ea88c74d89a20437b63f9abb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_cascade = cv.CascadeClassifier('../input/haarcascades/haarcascade_frontalface_default.xml')\n",
    "image_train = '../input/trainimages/images_train/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9686de3f2f503b32dcccc8a1b4846fec407e1262",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deleting = ['Abdul_Majeed_Shobokshi_0001.jpg',\n",
    " 'Arsinee_Khanjian_0001.jpg',\n",
    " 'Avinash_30.jpg',\n",
    " 'Colin_Montgomerie_0004.jpg',\n",
    " 'Colin_Powell_0048.jpg',\n",
    " 'David_McCullough_0001.jpg',\n",
    " 'Donald_Rumsfeld_0117.jpg',\n",
    " 'Fernando_Vargas_0004.jpg',\n",
    " 'Franz_Muentefering_0003.jpg',\n",
    " 'George_HW_Bush_0003.jpg',\n",
    " 'George_Pataki_0002.jpg',\n",
    " 'Hans_Blix_0016.jpg',\n",
    " 'Isaiah_Washington_0002.jpg',\n",
    " 'Jeff_Feldman_0001.jpg',\n",
    " 'Jiang_Zemin_0002.jpg',\n",
    " 'Jiang_Zemin_0007.jpg',\n",
    " 'Joe_Vandever_0001.jpg',\n",
    " 'John_Wright_0001.jpg',\n",
    " 'Kimberly_Bruckner_0001.jpg',\n",
    " 'Kimberly_Stewart_0001.jpg',\n",
    " 'Kimi_Raikkonen_0001.jpg',\n",
    " 'Kimi_Raikkonen_0002.jpg',\n",
    " 'Kimi_Raikkonen_0003.jpg',\n",
    " 'Kimora_Lee_0001.jpg',\n",
    " 'Lin_Yi-fu_0001.jpg',\n",
    " 'Luciano_Pavarotti_0002.jpg',\n",
    " 'Lynne_Thigpen_0001.jpg',\n",
    " 'Michael_Powell_0003.jpg',\n",
    " 'Miguel_Contreras_0001.jpg',\n",
    " 'Morgan_Freeman_0002.jpg',\n",
    " 'Padraig_Harrington_0004.jpg',\n",
    " 'Paul_Bremer_0014.jpg',\n",
    " 'Pedro_Malan_0003.jpg',\n",
    " 'Pierce_Brosnan_0007.jpg',\n",
    " 'Pyar_Jung_Thapa_0001.jpg',\n",
    " 'Richard_Gephardt_0007.jpg',\n",
    " 'Robert_Horan_0002.jpg',\n",
    " 'Robert_Zoellick_0005.jpg',\n",
    " 'Rob_Moore_0001.jpg',\n",
    " 'Scott_McNealy_0001.jpg',\n",
    " 'Thomas_Daily_0001.jpg',\n",
    " 'Tony_Blair_0090.jpg',\n",
    " 'William_Bulger_0002.jpg',\n",
    " 'Will_Ferrell_0001.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1609356900307e8287ad2ad66e369f1d2417f213",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "663271ad971de46256d366adeab34b5bc9e24b6e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for img in glob.glob(image_train+\"/*.jpg\"):\n",
    "    image = cv.imread(img)\n",
    "    name = img.split('/')[-1]\n",
    "    \n",
    "    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY) # convert to greyscale\n",
    "    height, width = image.shape[:2]\n",
    "    faces = face_cascade.detectMultiScale(gray_image, 1.3, 1)\n",
    "    if isinstance(faces, tuple):\n",
    "        resized_image = cv.resize(gray_image, (48, 48))\n",
    "        cv.imwrite(trained+'/'+name,resized_image)\n",
    "    #print(faces)\n",
    "    elif isinstance(faces, np.ndarray):\n",
    "        for (x,y,w,h) in faces:\n",
    "            if w * h < (height * width) / 3:\n",
    "                resized_image = cv.resize(gray_image, (48, 48)) \n",
    "                cv.imwrite(trained+'/'+name,resized_image)\n",
    "            else:\n",
    "                \n",
    "                #cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "                roi_gray = gray_image[y:y+h, x:x+w]\n",
    "                #print(len(roi_gray))\n",
    "                resized_image = cv.resize(roi_gray, (48, 48))\n",
    "                cv.imwrite(trained+'/'+name, resized_image)\n",
    "    if not name in deleting:\n",
    "        data.append(img_to_array(resized_image))\n",
    "        label = int(train_csv[ train_csv['image'] == name][['label']].values)\n",
    "        #print(label, type(label), name)\n",
    "        labels.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b1615bbe93992968ebf362d6a09ad6e1255d93c3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int(train_csv[ train_csv['image'] == 'Al_Sharpton_0004.jpg'][['label']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67244e626ef4905490d496ab4d3c53a52366dcec",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(labels), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6cd171d4f2b688e1ccf8cbd2be42617260ccd57b",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type(data), type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "426defbe5de9c7c5e27b39345d5ca83c9053b21e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] data matrix: {:.2f}MB\".format(data.nbytes / (1024 * 1000.0)))\n",
    "print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "de640cb4b2e8c71146633908fc13fc9f95d79e51",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "08f2f04149ca948c39144bc0e467a2d4d8620ee4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 70% of\n",
    "# the data for training and the remaining 30% for testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "(trainX, valX, trainY, valY) = train_test_split(data,labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ec84b78e5ec7e24e365267bf5be117734825fa65"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0bf43ba53daf3d43ffdd746ed9bd47ced59f1a57",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45fb9983f70c77158a37a1c617b5099b0e20e1af",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildModel(width, height, depth, classes):\n",
    "\t\t# initialize the model along with the input shape to be\n",
    "\t\t# \"channels last\" and the channels dimension itself\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\t\tchanDim = -1\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\t# and channels dimension\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\t\t\tchanDim = 1\n",
    "\n",
    "\t\t# CONV => RELU => POOL\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\",\n",
    "\t\t\tinput_shape=inputShape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# (CONV => RELU) * 2 => POOL\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# (CONV => RELU) * 2 => POOL\n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(1024))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "771825ca6980a3ad9c3dcd5e17ce298a748bb484",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# batch size, and image dimensions\n",
    "EPOCHS = 100\n",
    "INIT_LR = 1e-3\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ba2b2e03d432921219778a2b04e1ecd736db4b40",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = buildModel(width=48, height=48,depth=1, classes=len(lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "621f465058bc41b972a6a2052c60fc178f9af846",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aa8bfd828039f0522c1db8f79c9107ed0baccc01",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0beb35e506be223d208038c62b47f095d10d7e6e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d387aada491fb78c0800b7b55c5aeed439b7127e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = model.fit_generator(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(valX, valY),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tepochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8bb547a9f49229802a889a7fd1b3491b8c8cc70c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('../input/emotion.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "424db398be3f8cb2b16a6b9c547a6c439d57de42",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "19068cad216e2c289c42ad16428e2324a22f4507",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"../input/lb.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db55ca95820f3c88a56971d335a1eb6a78cf5997"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d471d5eee164913cfd4aa771a9f3b7eb2da68f9f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_path = '../input/prediction/prediction/57b.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f2668c337619032219a7364ff9f913af4a5e5f4",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "64bcbe3b29b12c2f0521fca17217cb7b59d458bb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv.imread(image_path)\n",
    "image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "image = cv.resize(image, (48, 48))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb5fcd1f33e241d035baa9bcfdb933be2e691ac7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ee63cbbf95a9259685b278661fbd7663f3f486f2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../input/facial-expression-recognitionferchallenge/fer2013/fer2013/fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "169bb258a3e0dd15313c8184fe159e3e434c561f",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test = df_test.sample(frac=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8cba5dabc8051a0436735059b8d2345173a6bf33",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "test_index = df_test.index\n",
    "for item in df_test.index:\n",
    "    pixels = df_test.pixels[item]\n",
    "    pixels = pixels.split(' ')\n",
    "    piarray = np.asarray(pixels, dtype=np.int64)\n",
    "    re = piarray.reshape(48,48)\n",
    "    X_test.append(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ab576c7cf63620ecf32457d4c17e5384fd80a522",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.asarray(X_test)\n",
    "X_test = np.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c03cee4629db223498a9d4f14ea252b27e2a1ea0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6ae0f365eda400d6a3936fa9999f4acc77d93704",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"proba = model.predict(image)[0]\n",
    "idx = np.argmax(proba)\n",
    "label = lb.classes_[idx]\n",
    "\"\"\"\n",
    "Y_predict = []\n",
    "for item in X_test:\n",
    "    item = np.expand_dims(item, axis = 0)\n",
    "    predict = model.predict(item)\n",
    "    idx = np.argmax(predict)\n",
    "    label = lb.classes_[idx]\n",
    "    Y_predict.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "44e268b3606ed230c95dc40c6e2bf4d1e6fc1f4a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_true = df_test.emotion.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3aa458fb2917a531d98bacb2fbf37ff9811d1b80",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_true, Y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46429b73bc4fd3a5df2a1762cdf41d4349ec8ef4",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f1437929bfaa7ff39c1f9b5fc81a254ed2b57ca8",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
